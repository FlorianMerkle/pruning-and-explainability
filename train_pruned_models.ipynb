{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d04287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from load_models import load_mobilenet, load_resnet\n",
    "from load_data import load_imagenette\n",
    "from utils import batch_accuracy\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff7294",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0112a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOBILENET_PATH = './models/MobileNetV3Small.pt'\n",
    "model = load_mobilenet(MOBILENET_PATH).to(device)\n",
    "\n",
    "RESNET_PATH = './models/ResNet18.pt'\n",
    "model = load_resnet(RESNET_PATH).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923df77",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9e7645",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/florian/data/imagenette2'\n",
    "train_dl, val_dl = load_imagenette(PATH, 128, normalize=False)\n",
    "\n",
    "\n",
    "\n",
    "image = next(iter(train_dl))[0][1].unsqueeze(0).to(device)\n",
    "img_batch, label_batch = next(iter(train_dl))\n",
    "img_batch, label_batch = img_batch.to(device), label_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f209840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(model, img_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0eaf2",
   "metadata": {},
   "source": [
    "# Prune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786ede9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77541896",
   "metadata": {},
   "source": [
    "### Identify Modules to Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbc7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prunable_modules(model):\n",
    "    modules_to_prune = []\n",
    "    for i, m in enumerate(list(model.named_modules())):\n",
    "        if isinstance(m[1], torch.nn.Conv2d):\n",
    "            modules_to_prune.append(model.get_submodule(m[0]))\n",
    "    return modules_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e3d7887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modules_to_prune = get_prunable_modules(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcfdd076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to determine the min, max and average sparsity of the prunable modules\n",
    "def get_sparsity(modules):\n",
    "    sparsities = []\n",
    "    for m in modules:\n",
    "        sparsities.append(((m.weight == 0).sum()/m.weight.numel()).item())\n",
    "    sparsities = torch.Tensor(sparsities)\n",
    "    return {\n",
    "        'min':sparsities.min().item(), \n",
    "        'max':sparsities.max().item(), \n",
    "        'mean':sparsities.mean().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab92065",
   "metadata": {},
   "source": [
    "### Pre Pruning Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dd317fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(model, img_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b6e79c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.0, 'max': 0.0, 'mean': 0.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(modules_to_prune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31068ada",
   "metadata": {},
   "source": [
    "### Apply Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da39fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_prune(modules, amount):\n",
    "    for m in modules:\n",
    "        prune.L1Unstructured(.0).apply(m, 'weight', amount)\n",
    "    return get_sparsity(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8035564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.875, 'max': 0.875, 'mean': 0.875}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_prune(modules_to_prune, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6f150",
   "metadata": {},
   "source": [
    "### Post Pruning Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b0f17af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3281"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(model, img_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3ec5f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.5, 'max': 0.5, 'mean': 0.5}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(modules_to_prune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121b68a",
   "metadata": {},
   "source": [
    "# Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4e7ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR-1\n",
      "0.9766\n",
      "{'min': 0.0, 'max': 0.0, 'mean': 0.0}\n",
      "CPR-2\n",
      "Training complete in 9m 45s\n",
      "Best val Acc: 0.929682\n",
      "0.9766\n",
      "{'min': 0.5, 'max': 0.5, 'mean': 0.5}\n",
      "CPR-4\n",
      "Training complete in 9m 45s\n",
      "Best val Acc: 0.897325\n",
      "0.9531\n",
      "{'min': 0.75, 'max': 0.75, 'mean': 0.75}\n",
      "CPR-8\n",
      "Training complete in 9m 48s\n",
      "Best val Acc: 0.802803\n",
      "0.8438\n",
      "{'min': 0.875, 'max': 0.875, 'mean': 0.875}\n",
      "CPR-16\n",
      "Training complete in 9m 47s\n",
      "Best val Acc: 0.577580\n",
      "0.6328\n",
      "{'min': 0.9375, 'max': 0.9375, 'mean': 0.9375}\n",
      "CPR-32\n",
      "Training complete in 9m 46s\n",
      "Best val Acc: 0.245350\n",
      "0.2109\n",
      "{'min': 0.96875, 'max': 0.96875, 'mean': 0.96875}\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "RESNET_PATH = './models/ResNet18.pt'\n",
    "model = load_resnet(RESNET_PATH).to(device)\n",
    "modules_to_prune = get_prunable_modules(model)\n",
    "\n",
    "dataloaders = {\n",
    "    'train':train_dl, \n",
    "    'val':val_dl\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train':len(train_dl.dataset), \n",
    "    'val':len(val_dl.dataset)\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print('CPR-1')\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "print('CPR-2')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR2-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR2-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-4')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR4-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR4-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-8')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR8-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR8-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-16')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR16-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR16-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-32')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR32-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR32-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d3c348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR-1\n",
      "0.9766\n",
      "{'min': 0.0, 'max': 0.0, 'mean': 0.0}\n",
      "CPR-2\n",
      "Training complete in 38m 56s\n",
      "Best val Acc: 0.935541\n",
      "0.9844\n",
      "{'min': 0.5, 'max': 0.5, 'mean': 0.5}\n",
      "CPR-4\n",
      "Training complete in 39m 7s\n",
      "Best val Acc: 0.903185\n",
      "0.9609\n",
      "{'min': 0.75, 'max': 0.75, 'mean': 0.75}\n",
      "CPR-8\n",
      "Training complete in 39m 5s\n",
      "Best val Acc: 0.779873\n",
      "0.8516\n",
      "{'min': 0.875, 'max': 0.875, 'mean': 0.875}\n",
      "CPR-16\n",
      "Training complete in 39m 9s\n",
      "Best val Acc: 0.543949\n",
      "0.5703\n",
      "{'min': 0.9375, 'max': 0.9375, 'mean': 0.9375}\n",
      "CPR-32\n",
      "Training complete in 39m 11s\n",
      "Best val Acc: 0.241274\n",
      "0.2891\n",
      "{'min': 0.96875, 'max': 0.96875, 'mean': 0.96875}\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "RESNET_PATH = './models/ResNet18.pt'\n",
    "model = load_resnet(RESNET_PATH).to(device)\n",
    "modules_to_prune = get_prunable_modules(model)\n",
    "\n",
    "dataloaders = {\n",
    "    'train':train_dl, \n",
    "    'val':val_dl\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train':len(train_dl.dataset), \n",
    "    'val':len(val_dl.dataset)\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print('CPR-1')\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "print('CPR-2')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR2-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR2-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-4')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR4-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR4-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-8')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR8-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR8-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-16')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR16-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR16-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "print('CPR-32')\n",
    "l1_prune(modules_to_prune, .5)\n",
    "cpr2_state_dict = train_model(model, dataloaders, criterion, optimizer,exp_lr_scheduler, num_epochs=EPOCHS)\n",
    "print(batch_accuracy(model, img_batch, label_batch))\n",
    "print(get_sparsity(modules_to_prune))\n",
    "\n",
    "SAVE_PATH = './models/CPR32-ResNet18.pt'\n",
    "#SAVE_PATH = './models/CPR32-MobileNet.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce37f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d4205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29487770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1ceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            #    phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "515ba8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(model[1].layer1[0].conv1, 'weight', .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "94219ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((3,3));t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2895a452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 0., 1.]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.L1Unstructured(.1).prune(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9be8ca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.nn.utils.prune.L1Unstructured at 0x7fa43421a2e0>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.L1Unstructured(.1).apply(model[1].layer1[0].conv2, 'weight', .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "eb34c2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5500, device='cuda:0')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model[1].layer1[0].conv2.weight == 0).sum() / model[1].layer1[0].conv2.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "53e5387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5500, device='cuda:0')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model[1].layer1[0].conv1.weight == 0).sum() / model[1].layer1[0].conv1.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d55cc19f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'conv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_915222/2028951937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomUnstructured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/PT/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'conv2'"
     ]
    }
   ],
   "source": [
    "prune.RandomUnstructured(model[1].conv1, 'weight', .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88680f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2369]],\n",
       "\n",
       "         [[ 0.3606]],\n",
       "\n",
       "         [[-0.0933]]],\n",
       "\n",
       "\n",
       "        [[[-0.0698]],\n",
       "\n",
       "         [[-0.3554]],\n",
       "\n",
       "         [[ 0.3857]]],\n",
       "\n",
       "\n",
       "        [[[-0.5537]],\n",
       "\n",
       "         [[-0.1553]],\n",
       "\n",
       "         [[-0.4332]]]], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.nn.Conv2d(3,3,1)\n",
    "t.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30003d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prune.l1_unstructured(t, 'weight',.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8198b8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2369]],\n",
       "\n",
       "         [[ 0.3606]],\n",
       "\n",
       "         [[-0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000]],\n",
       "\n",
       "         [[-0.3554]],\n",
       "\n",
       "         [[ 0.3857]]],\n",
       "\n",
       "\n",
       "        [[[-0.5537]],\n",
       "\n",
       "         [[-0.0000]],\n",
       "\n",
       "         [[-0.4332]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.ran"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
